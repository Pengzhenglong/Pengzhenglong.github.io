

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/2.jpg">
  <link rel="icon" href="/img/2.jpg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="DragonPeng">
  <meta name="keywords" content="">
  
  <title>拆解追溯 GPT-3.5 各项能力的起源 - DragonPeng的博客</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.4.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.9","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>DragonPeng' blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/page1.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="拆解追溯 GPT-3.5 各项能力的起源">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2023-03-26 18:15" pubdate>
        March 26, 2023 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      6.7k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      73
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">拆解追溯 GPT-3.5 各项能力的起源</h1>
            
            <div class="markdown-body">
              <hr>
<h3 id="拆解追溯-GPT-3-5-各项能力的起源"><a href="#拆解追溯-GPT-3-5-各项能力的起源" class="headerlink" title="拆解追溯 GPT-3.5 各项能力的起源"></a>拆解追溯 GPT-3.5 各项能力的起源</h3><h4 id="一、2020-版初代-GPT-3-与大规模预训练"><a href="#一、2020-版初代-GPT-3-与大规模预训练" class="headerlink" title="# 一、2020 版初代 GPT-3 与大规模预训练"></a># 一、2020 版初代 GPT-3 与大规模预训练</h4><p>初代GPT-3展示了三个重要能力：</p>
<ul>
<li><strong>语言生成</strong>：遵循提示词（prompt），然后生成补全提示词的句子 (completion)。这也是今天人类与语言模型最普遍的交互方式。</li>
<li><strong>上下文学习 (in-context learning)</strong>:  遵循给定任务的几个示例，然后为新的测试用例生成解决方案。很重要的一点是，GPT-3虽然是个语言模型，但它的论文几乎没有谈到“语言建模” (language modeling) —— 作者将他们全部的写作精力都投入到了对上下文学习的愿景上，这才是 GPT-3的真正重点。</li>
<li>**世界知识 (world knowledge)**：包括事实性知识 (factual knowledge) 和常识 (commonsense)。</li>
</ul>
<p>那么这些能力从何而来呢？</p>
<p>基本上，以上三种能力都来自于大规模预训练：在有3000亿单词的语料上预训练拥有1750亿参数的模型（ 训练语料的60%来自于 2016 - 2019 的 C4 + 22% 来自于 WebText2 + 16% 来自于Books + 3%来自于Wikipedia）。其中：</p>
<ul>
<li><strong>语言生成</strong>的能力来自于语言建模的<strong>训练目标</strong> (language modeling)。</li>
<li><strong>世界知识</strong>来自 3000 亿单词的<strong>训练语料库</strong>（不然还能是哪儿呢）。</li>
<li><strong>模型的 1750 亿参数</strong>是为了<strong>存储知识</strong>，Liang et al. (2022) 的文章进一步证明了这一点。 他们的结论是，知识密集型任务的性能与模型大小息息相关。</li>
<li>上下文学习的能力来源及为什么上下文学习可以泛化，<strong>仍然难以溯源。</strong>直觉上，这种能力可能来自于同一个任务的数据点在训练时按顺序排列在同一个 batch 中。然而，很少有人研究为什么语言模型预训练会促使上下文学习，以及为什么上下文学习的行为与微调 (fine-tuning) 如此不同。</li>
</ul>
<p>令人好奇的是，初代<strong>的GPT-3有多强。</strong><br>其实比较难确定初代 GPT-3（在 OpenAI API 中被称为<code>davinci</code>）到底是“强”还是“弱”。一方面，它合理地回应了某些特定的查询，并在许多数据集中达到了还不错的性能；另一方面，它在许多任务上的<strong>表现还不如 T5 这样的小模型</strong>（参见其原始论文）。在今天（2022 年 12 月）ChatGPT 的标准下，很难说初代的 GPT-3 是“智能的”。Meta 开源的 OPT 模型试图复现初代 GPT-3，但它的能力与当今的标准也形成了尖锐的对比。许多测试过 OPT 的人也认为与现在的<code>text-davinci-002</code>相比，该模型确实 “不咋地”。尽管如此，OPT 可能是初代 GPT-3 的一个足够好的开源的近似模型了（根据 OPT 论文和斯坦福大学的 HELM 评估）。</p>
<p>虽然初代的 GPT-3 可能表面上看起来很弱，但后来的实验证明，初代 GPT-3 有着非常强的潜力。这些潜力后来被代码训练、指令微调 (instruction tuning) 和基于人类反馈的强化学习 (reinforcement learning with human feedback, RLHF) 解锁，最终体展示出极为强大的突现能力。</p>
<h4 id="二、从-2020-版-GPT-3-到-2022-版-ChatGPT"><a href="#二、从-2020-版-GPT-3-到-2022-版-ChatGPT" class="headerlink" title="# 二、从 2020 版 GPT-3 到 2022 版 ChatGPT"></a># 二、从 2020 版 GPT-3 到 2022 版 ChatGPT</h4><p>从最初的 GPT-3 开始，为了展示 OpenAI 是如何发展到ChatGPT的，我们看一下 GPT-3.5 的进化树：</p>
<p><img src="/img/chatGPT.png" srcset="/img/loading.gif" lazyload alt="chatGPT"></p>
<p>在 <strong>2020 年 7 月</strong>，OpenAI 发布了模型索引为的 <code>davinci</code> 的初代 GPT-3 论文，从此它就开始不断进化。在 <strong>2021 年 7 月</strong>，Codex 的论文发布，其中初始的 Codex 是根据（可能是内部的）120 亿参数的 GPT-3 变体进行微调的。后来这个 120 亿参数的模型演变成 OpenAI API 中的<code>code-cushman-001</code>。在 <strong>2022 年 3 月</strong>，OpenAI 发布了指令微调 (instruction tuning) 的论文，其监督微调 (supervised instruction tuning) 的部分对应了<code>davinci-instruct-beta</code>和<code>text-davinci-001</code>。在 <strong>2022 年 4 月至 7 月的</strong>，OpenAI 开始对<code>code-davinci-002</code>模型进行 Beta 测试，也称其为 Codex。然后<code>code-davinci-002</code>、<code>text-davinci-003</code>和<code>ChatGPT</code> 都是从<code>code-davinci-002</code>进行指令微调得到的。详细信息请参阅 OpenAI的模型索引文档。</p>
<p>尽管 Codex 听着像是一个只管代码的模型，但<code>code-davinci-002</code>可能是最强大的针对<strong>自然语言</strong>的GPT-3.5 变体（优于 <code>text-davinci-002</code>和 <code>-003</code>）。<code>code-davinci-002</code>很可能在文本和代码上都经过训练，然后根据指令进行调整（将在下面解释）。然后<strong>2022 年 5-6 月</strong>发布的<code>text-davinci-002</code>是一个基于<code>code-davinci-002</code>的有监督指令微调 (supervised instruction tuned) 模型。在<code>text-davinci-002</code>上面进行<strong>指令微调</strong>很可能<strong>降低</strong>了模型的<strong>上下文学习</strong>能力<strong>，</strong>但是<strong>增强了</strong>模型的<strong>零样本能力</strong>（将在下面解释）。然后是<code>text-davinci-003</code>和 <code>ChatGPT</code>，它们都在 <strong>2022 年 11 月</strong>发布，是使用的基于人类反馈的强化学习的版本指令微调 (instruction tuning with reinforcement learning from human feedback) 模型的两种不同变体。<code>text-davinci-003</code> 恢复了（但仍然比<code>code-davinci-002</code>差）一些在<code>text-davinci-002</code> 中丢失的部分<strong>上下文学习能</strong>力（大概是因为它在微调的时候混入了语言建模） 并进一步改进了零样本能力（得益于RLHF）。另一方面，ChatGPT 似乎<strong>牺牲了几乎所有的上下文学习的能力</strong>来<strong>换取</strong>建模对话历史的能力。</p>
<p>总的来说，在 2020 - 2021 年期间，在<code>code-davinci-002</code>之前，OpenAI 已经投入了大量的精力通过代码训练和指令微调来增强GPT-3。当他们完成<code>code-davinci-002</code>时，所有的能力都已经存在了。很可能后续的指令微调，无论是通过有监督的版本还是强化学习的版本，都会做以下事情（稍后会详细说明）：</p>
<ul>
<li>指令微调<strong>不会为模型注入新的能力</strong> —— 所有的能力都已经存在了。指令微调的作用是<strong>解锁 / 激发这些能力</strong>。这主要是因为指令微调的数据量比预训练数据量少几个数量级（基础的能力是通过预训练注入的）。</li>
<li>指令微调<strong>将 GPT-3.5 的分化到不同的技能树。</strong>有些更擅长上下文学习，如<code>text-davinci-003</code>，有些更擅长对话，如<code>ChatGPT</code>。</li>
<li>指令微调<strong>通过牺牲性能换取与人类的对齐（alignment）</strong>。 OpenAI 的作者在他们的指令微调论文中称其为 “对齐税” (alignment tax)。许多论文都报道了<code>code-davinci-002</code>在基准测试中实现了最佳性能（但模型不一定符合人类期望）。 在<code>code-davinci-002</code>上进行指令微调后，模型可以生成更加符合人类期待的反馈（或者说模型与人类对齐），例如：零样本问答、生成安全和公正的对话回复、拒绝超出模型它知识范围的问题。</li>
</ul>
<h4 id="三、Code-Davinci-002和-Text-Davinci-002，在代码上训练，在指令上微调"><a href="#三、Code-Davinci-002和-Text-Davinci-002，在代码上训练，在指令上微调" class="headerlink" title="# 三、Code-Davinci-002和 Text-Davinci-002，在代码上训练，在指令上微调"></a># 三、Code-Davinci-002和 Text-Davinci-002，在代码上训练，在指令上微调</h4><p>在<code>code-davinci-002</code>和<code>text-davinci-002</code>之前，有两个中间模型，分别是 davinci-instruct-beta 和 text-davinci-001。两者在很多方面都比上述的两个-002模型差（例如，text-davinci-001 链式思维推理能力不强）。所以我们在本节中重点介绍 -002 型号。</p>
<h5 id="3-1-复杂推理能力的来源和泛化到新任务的能力"><a href="#3-1-复杂推理能力的来源和泛化到新任务的能力" class="headerlink" title="3.1 复杂推理能力的来源和泛化到新任务的能力"></a><strong>3.1 复杂推理能力的来源和泛化到新任务的能力</strong></h5><p>我们关注<code>code-davinci-002</code>和<code>text-davinci-002</code>，这两兄弟是第一版的 GPT3.5 模型，一个用于代码，另一个用于文本。它们表现出了四种与初代 GPT-3 不同的重要能力：</p>
<ul>
<li><strong>响应人类指令</strong>：以前，GPT-3 的输出主要训练集中常见的句子。现在的模型会针对指令 / 提示词生成更合理的答案（而不是相关但无用的句子）。</li>
<li><strong>泛化到没有见过的任务</strong>：当用于调整模型的指令数量超过一定的规模时，模型就可以自动在从没见过的新指令上也能生成有效的回答。 <strong>这种能力对于上线部署至关重要</strong>，因为用户总会提新的问题，模型得答得出来才行。</li>
<li><strong>代码生成和代码理解</strong>：这个能力很显然，因为模型用代码训练过。</li>
<li><strong>利用思维链 (chain-of-thought) 进行复杂推理</strong>：初代 GPT3 的模型思维链推理的能力很弱甚至没有。 <strong>code-davinci-002 和 text-davinci-002 是两个拥有足够强的思维链推理能力的模型。</strong><ul>
<li>思维链推理之所以重要，是因为思维链可能是解锁突现能力和超越缩放法则 (scaling laws) 的关键。请参阅上一篇博文。</li>
</ul>
</li>
</ul>
<p>这些能力从何而来？</p>
<p>与之前的模型相比，两个主要区别是<strong>指令微调</strong>和<strong>代码训练</strong>。具体来说</p>
<ul>
<li>能够<strong>响应人类指令</strong>的能力是<strong>指令微调</strong>的直接产物。</li>
<li><strong>对没有见过的指令做出反馈</strong>的泛化能力是在指令数量超过一定程度之后<strong>自动出现的</strong>，T0、Flan 和 FlanPaLM 论文进一步证明了这一点</li>
<li>使用<strong>思维链</strong>进行<strong>复杂推理</strong>的能力很可能是<strong>代码训练</strong>的<strong>一个神奇的副产物</strong>。对此，我们有以下的事实作为一些支持：<ul>
<li>最初的 GPT-3 没有接受过代码训练，它不能做<strong>思维链</strong>。</li>
<li>text-davinci-001 模型，虽然经过了指令微调，但第一版思维链论文报告说，它的它思维链推理的能力非常弱 —— <strong>所以指令微调可能不是思维链存在的原因，代码训练才是模型能做思维链推理的最可能原因。</strong></li>
<li>PaLM 有 5% 的代码训练数据，可以做思维链。</li>
<li>Codex论文中的代码数据量为 159G ，大约是初代 GPT-3 5700 亿训练数据的28%。code-davinci-002 及其后续变体可以做思维链推理。</li>
<li>在 HELM 测试中，Liang et al. (2022) 对不同模型进行了大规模评估。 他们发现了针对代码训练的模型具有很强的语言推理能力，包括 120亿参数的code-cushman-001.。</li>
<li>我们在 AI2 的工作也表明，当配备复杂的思维链时，code-davinci-002 在 GSM8K 等重要数学基准上是目前表现最好的模型</li>
<li>直觉来说，<strong>面向过程的编程 (procedure-oriented programming)</strong> 跟人类<strong>逐步解决任务</strong>的过程很类似，<strong>面向对象编程 (object-oriented programming)</strong> 跟人类<strong>将复杂任务分解为多个简单任务</strong>的过程很类似。</li>
<li>以上所有观察结果都是代码与推理能力 / 思维链 之间的相关性，但不一定是因果性。这种相关性很有趣，但现在还是一个待研究的开放性问题。目前看来，我们<strong>没有非常确凿的证据证明代码就是思维链和复杂推理的原因</strong>。</li>
</ul>
</li>
<li>此外， <strong>代码训练</strong>另一个可能的副产品是<strong>长距离依赖，</strong>正如Peter Liu所指出：“语言中的下个词语预测通常是非常局部的，而代码通常需要更长的依赖关系来做一些事情，比如前后括号的匹配或引用远处的函数定义”。这里我想进一步补充的是：由于面向对象编程中的类继承，代码也可能有助于模型建立编码层次结构的能力。我们将对这一假设的检验留给未来的工作。</li>
</ul>
<p>另外还要注意一些细节差异：</p>
<ul>
<li><strong>text-davinci-002 与 code-davinci-002</strong><ul>
<li>Code-davinci-002 是基础模型，text-davinci-002 是指令微调 code-davinci-002 的产物（见 OpenAI 的文档）。它在以下数据上作了微调：（一）人工标注的指令和期待的输出；（二）由人工标注者选择的模型输出。</li>
<li>当有上下文示例 (in-context example) 的时候， Code-davinci-002 更擅长上下文学习；当没有上下文示例 / 零样本的时候， text-davinci-002 在零样本任务完成方面表现更好。从这个意义上说，text-davinci-002 更符合人类的期待（因为对一个任务写上下文示例可能会比较麻烦）。</li>
<li>OpenAI 不太可能故意牺牲了上下文学习的能力换取零样本能力 —— 上下文学习能力的降低更多是指令学习的一个副作用，OpenAI 管这叫对齐税。</li>
</ul>
</li>
<li><strong>001 模型（code-cushman-001 和 text-davinci-001）v.s. 002 模型（code-davinci-002 和 text-davinci-002）</strong><ul>
<li>001 模型主要是为了做纯代码 / 纯文本任务； 002 模型则深度融合了代码训练和指令微调，代码和文本都行。</li>
<li>Code-davinci-002 可能是第一个深度融合了代码训练和指令微调的模型。证据有：code-cushman-001 可以进行推理但在纯文本上表现不佳，text-davinci-001 在纯文本上表现不错但在推理上不大行。 code-davinci-002 则可以同时做到这两点。</li>
</ul>
</li>
</ul>
<h5 id="3-2-这些能力是在预训练之后已经存在还是在之后通过微调注入？"><a href="#3-2-这些能力是在预训练之后已经存在还是在之后通过微调注入？" class="headerlink" title="3.2 这些能力是在预训练之后已经存在还是在之后通过微调注入？"></a>3.2 <strong>这些能力是在预训练之后已经存在还是在之后通过微调注入？</strong></h5><p>在这个阶段，我们已经确定了指令微调和代码训练的关键作用。一个重要的问题是如何进一步分析代码训练和指令微调的影响？具体来说：<br>上述三种能力是否<strong>已经存在于初代的GPT-3</strong>中，只是<strong>通过指令和代码训练触发 / 解锁</strong>？ 或者这些能力在初代的 GPT-3 中<strong>并不存在</strong>，是通过指令和代码训练<strong>注入？</strong><br>如果答案已经在初代的 GPT-3 中，<strong>那么这些能力也应该在 OPT 中。 因此，要复现这些能力，或许可以直接通过指令和代码调整 OPT。</strong> 但是，code-davinci-002 也可能不是基于最初的 GPT-3 davinci，而是基于比初代 GPT-3 更大的模型。如果是这种情况，可能就没办法通过调整 OPT 来复现了。研究社区需要进一步弄清楚 OpenAI 训练了什么样的模型作为 code-davinci-002 的基础模型。</p>
<p>我们有以下的假设和证据：</p>
<ul>
<li>code-davinci-002的<strong>基础模型可能不是初代GPT-3 davinci 模型</strong>。以下是证据：<ul>
<li>初代的GPT-3在数据集 C4 2016 - 2019 上训练，而 code-davinci-002 训练集则在延长到2021年才结束。因此 code-davinci-002 有可能在 C4 的 2019-2021 版本上训练。</li>
<li>初代的 GPT-3 有一个大小为 <strong>2048</strong> 个词的上下文窗口。code-davinci-002 的上下文窗口则为 <strong>8192</strong>。GPT 系列使用绝对位置嵌入 (absolute positional embedding)，直接对绝对位置嵌入进行外推而不经过训练是比较难的，并且会严重损害模型的性能（参考 Press et al., 2022）。如果 code-davinci-002 是基于初代GPT-3，那OpenAI 是如何扩展上下文窗口的？</li>
</ul>
</li>
<li>另一方面，无论基础模型是初代的 GPT-3 还是后来训练的模型， <strong>遵循指令和零样本泛化的能力都可能已经存在于基础模型</strong>中，后来才通过指令微调来<strong>解锁</strong> （<strong>而不是注入）</strong><ul>
<li>这主要是因为 OpenAI 的论文报告的指令数据量大小只有 77K，比预训练数据少了几个数量级。</li>
<li>其他指令微调论文进一步证明了数据集大小对模型性能的对比，例如 Chung et al. (2022) 的工作中， Flan-PaLM 的指令微调仅为预训练计算的 0.4%。一般来说，指令数据会显著少于预训练数据。</li>
</ul>
</li>
<li>然而 <strong>，模型的复杂推理能力可能是在预训练阶段通过代码数据注入</strong><ul>
<li>代码数据集的规模与上述指令微调的情况不同。这里的代码数据量足够大，可以占据训练数据的重要部分（例如，PaLM 有 8% 的代码训练数据）</li>
<li>如上所述，在 code-davinci-002 之前的模型 text-davinci-001 大概没有在代码数据上面微调过，所以它的推理 / 思维链能力是非常差的，正如第一版思维链论文中所报告的那样，有时甚至比参数量更小的 code-cushman-001 还差。</li>
</ul>
</li>
<li><strong>区分代码训练和指令微调效果的最好方法</strong>可能是<strong>比较 code-cushman-001、T5 和 FlanT5</strong><ul>
<li>因为它们具有相似的模型大小（110亿 和 120亿），相似的训练数据集 (C4)，它们最大的区别就是有没有在代码上训练过 / 有没有做过指令微调。</li>
<li>目前还没有这样的比较。我们把这个留给未来的研究。</li>
</ul>
</li>
</ul>
<h4 id="四、text-davinci-003-和-ChatGPT，基于人类反馈的强化学习-Reinforcement-Learning-from-Human-Feedback-RLHF-的威力"><a href="#四、text-davinci-003-和-ChatGPT，基于人类反馈的强化学习-Reinforcement-Learning-from-Human-Feedback-RLHF-的威力" class="headerlink" title="四、text-davinci-003 和 ChatGPT，基于人类反馈的强化学习(Reinforcement Learning from Human Feedback, RLHF) 的威力"></a>四、text-davinci-003 和 ChatGPT，基于人类反馈的强化学习(Reinforcement Learning from Human Feedback, RLHF) 的威力</h4><p>在当前阶段（2022 年 12 月）， text-davinci-002、text-davinci-003 和 ChatGPT之间<strong>几乎没有严格的统计上的比较</strong> ，主要是因为</p>
<ul>
<li>text-davinci-003 和 ChatGPT 在撰写本文时才发布不到一个月。</li>
<li>ChatGPT 不能通过 OpenAI API 被调用，所以想要在标准基准上测试它很麻烦。</li>
</ul>
<p>所以在这些模型之间的比较更多是<strong>基于研究社区的集体经验</strong> （统计上不是很严格）。不过，我们相信初步的描述性比较仍然可以揭示模型的机制。</p>
<p>我们首先注意到以下 text-davinci-002，text-davinci-003 和 ChatGPT 之间的比较：</p>
<ul>
<li>所有三个模型都经过<strong>指令微调</strong>。</li>
<li><strong>text-davinci-002</strong> 是一个经过<strong>监督学习指令微调</strong> (supervised instruction tuning) ****的模型</li>
<li><strong>text-davinci-003 和 ChatGPT</strong> 是<strong>基于人类反馈的强化学习的指令微调</strong> (Instruction tuning with Reinforcement Learning from Human Feedback, RLHF)。这是它们之间最显着的区别。</li>
</ul>
<p><strong>这意味着大多数新模型的行为都是 RLHF 的产物</strong>。</p>
<p>那么让我们看看 RLHF 触发的能力：</p>
<ul>
<li><strong>翔实的回应：</strong> text-davinci-003 的生成通常比 text-davinci-002长。 ChatGPT 的回应则更加冗长，以至于用户必须明确要求“用一句话回答我”，才能得到更加简洁的回答。这是 RLHF 的直接产物。</li>
<li><strong>公正的回应：</strong>ChatGPT 通常对涉及多个实体利益的事件（例如政治事件）给出非常平衡的回答。这也是RLHF的产物。</li>
<li><strong>拒绝不当问题：</strong>这是内容过滤器和由 RLHF 触发的模型自身能力的结合，过滤器过滤掉一部分，然后模型再拒绝一部分。</li>
<li><strong>拒绝其知识范围之外的问题：</strong>例如，拒绝在2021 年 6 月之后发生的新事件（因为它没在这之后的数据上训练过）。这是 RLHF 最神奇的部分，因为它使模型能够隐式地区分哪些问题在其知识范围内，哪些问题不在其知识范围内。</li>
</ul>
<p>有两件事情值得注意：</p>
<ul>
<li>所有的能力都是模型本来就有的， <strong>而不是通过RLHF 注入的</strong>。 RLHF 的作用是<strong>触发 / 解锁突现能力</strong>。这个论点主要来自于数据量大小的比较：因为与预训练的数据量相比，RLHF 占用的计算量 / 数据量要少得多。</li>
<li>模型<strong>知道它不知道什么不是通过编写规则来实现的，</strong> 而是通过RLHF解锁的。这是一个非常令人惊讶的发现，因为 RLHF 的最初目标是让模型生成符合人类期望的回答，这更多是让模型生成安全的句子，而不是让模型知道它不知道的内容。</li>
</ul>
<p>幕后发生的事情可能是：</p>
<ul>
<li>ChatGPT: 通过<strong>牺牲上下文学习</strong>的能力<strong>换取建模对话历史</strong>的能力。这是一个基于经验的观测结果，因为 ChatGPT 似乎不像 text-davinci-003 那样受到上下文演示的强烈影响。</li>
<li>text-davinci-003：<strong>恢复了</strong> text-davinci-002 所牺牲的<strong>上下文学习能力</strong>， <strong>提高零样本的能力</strong>。 <del>我们不确定这是否也是 RLHF 或其他东西的副产品。</del> 根据instructGPT的论文，这是来自于强化学习调整阶段混入了语言建模的目标（而不是 RLHF 本身）。</li>
</ul>
<h4 id="五、总结当前阶段-GPT-3-5-的进化历程"><a href="#五、总结当前阶段-GPT-3-5-的进化历程" class="headerlink" title="# 五、总结当前阶段 GPT-3.5 的进化历程"></a># 五、总结<strong>当前阶段 GPT-3.5 的进化历程</strong></h4><p>到目前为止，我们已经仔细检查了沿着进化树出现的所有能力，下表总结了演化路径：<br><img src="/img/chatGPT1.png" srcset="/img/loading.gif" lazyload alt="chatGPT1"></p>
<p>我们可以得出结论：</p>
<ul>
<li>语言生成能力 + 基础世界知识 + 上下文学习都是来自于预训练（<code>davinci</code>）</li>
<li>存储大量知识的能力来自 1750 亿的参数量。</li>
<li>遵循指令和泛化到新任务的能力来自于扩大指令学习中指令的数量（<code>Davinci-instruct-beta</code>)</li>
<li>执行复杂推理的能力很可能来自于代码训练（<code>code-davinci-002</code>）</li>
<li>生成中立、客观的能力、安全和翔实的答案来自与人类的对齐。具体来说：<ul>
<li>如果是监督学习版，得到的模型是<code>text-davinci-002</code></li>
<li>如果是强化学习版 (RLHF) ，得到的模型是<code>text-davinci-003</code></li>
<li>无论是有监督还是 RLHF ，模型在很多任务的性能都无法超过 code-davinci-002 ，这种因为对齐而造成性能衰退的现象叫做对齐税。</li>
</ul>
</li>
<li>对话能力也来自于 RLHF（<code>ChatGPT</code>），具体来说它牺牲了上下文学习的能力，来换取：<ul>
<li>建模对话历史</li>
<li>增加对话信息量</li>
<li>拒绝模型知识范围之外的问题</li>
</ul>
</li>
</ul>
<h4 id="六、GPT-3-5-目前不能做什么"><a href="#六、GPT-3-5-目前不能做什么" class="headerlink" title="# 六、GPT-3.5 目前不能做什么"></a># 六、<strong><strong>GPT-3.5 目前不能做什么</strong></strong></h4><p>虽然GPT-3.5是自然语言处理研究中的重要一步，但它并没有完全包含许多研究人员（包括 AI2）设想的所有理想属性。以下是GPT-3.5不具备的某些重要属性：</p>
<ul>
<li><strong>实时改写模型的信念</strong>：当模型表达对某事的信念时，如果该信念是错误的，我们可能很难纠正它：<ul>
<li>我最近遇到的一个例子是：ChatGPT 坚持认为 3599 是一个质数，尽管它承认 3599 = 59 * 61。另外，请参阅Reddit上关于游得最快的海洋哺乳动物的例子。</li>
<li>然而，模型信念的强度似乎存在不同的层次。一个例子是即使我告诉它达斯·维达（星球大战电影中的人物）赢得了2020年大选，模型依旧会认为美国现任总统是拜登。但是如果我将选举年份改为 2024 年，它就会认为总统是达斯·维达是 2026 年的总统。</li>
</ul>
</li>
<li><strong>形式推理</strong>：GPT-3.5系列不能在数学或一阶逻辑等形式严格的系统中进行推理：<ul>
<li>在自然语言处理的文献中， “推理” 一词的定义很多时候不太明确。但如果我们从模糊性的角度来看，例如一些问题 (a) 非常模棱两可，没有推理；(b) 有点儿逻辑在里面，但有些地方也可以模糊；(c) 非常严谨，不能有任何歧义。那么，</li>
<li>模型可以很好地进行 (b) 类的带模糊性的推理，例子有：<ul>
<li>生成如何做豆腐脑的方法。做豆腐脑的时候，中间很多步骤模糊一点是可以接受的，比如到底是做咸的还是做甜的。只要整体步骤大致正确，做出来的豆腐脑儿就能吃。</li>
<li>数学定理的证明思路。证明思路是用语言表达的非正式的逐步解法，其中每一步的严格推导可以不用太具体。证明思路经常被用到数学教学：只要老师给一个大致正确的整体步骤，学生就可以大概明白。然后老师把具体的证明细节作为作业布置给学生，答案略。</li>
</ul>
</li>
<li>GPT-3.5 不能进行类型 (c) 的推理（推理不能容忍歧义）。<ul>
<li>一个例子是严格的数学证明，要求中间步骤中不能跳，不能模糊，不能错。</li>
<li>但这种严格推理到底是应该让语言模型做还是让符号系统做还有待讨论。一个例子是，与其努力让 GPT 做三位数加法，不如直接调 Python。</li>
</ul>
</li>
</ul>
</li>
<li><strong>从互联网进行检索</strong>：GPT-3.5 系列（暂时）不能直接搜索互联网<ul>
<li>但是有一篇 WebGPT 论文发表于2021年12月，里面就让 GPT 调用了搜索引擎。所以检索的能力已经在 OpenAI 内部进行了测试。</li>
<li>这里需要区分的一点是，GPT-3.5 的两个重要但不同的能力是 <strong>知识</strong> 和 <strong>推理</strong>。一般来说，如果我们能够 <strong>将知识部分卸载到外部的检索系统，让语言模型只专注于推理，这就很不错了。</strong> 因为：<ul>
<li>模型的内部知识总是在某个时间被切断。模型始终需要最新的知识来回答最新的问题。</li>
<li>回想一下，我们已经讨论过 1750 亿的参数大量用于存储知识。如果我们可以将知识卸载到模型之外，那么模型参数可能会大大减少，最终它甚至可以在手机上运行（疯狂的想法，但 ChatGPT 已经足够科幻了，谁知道未来会怎样呢).</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="七、结论"><a href="#七、结论" class="headerlink" title="# 七、结论"></a># 七、结论</h4><p>在这篇博文中，我们仔细检查了GPT-3.5系列的能力范围，并追溯了它们所有突现能力的来源。初代GPT-3模型通过预训练获得生成能力、世界知识和in-context learning。然后通过instruction tuning的模型分支获得了遵循指令和能泛化到没有见过的任务的能力。经过代码训练的分支模型则获得了代码理解的能力，作为代码训练的副产品，模型同时潜在地获得了复杂推理的能力。结合这两个分支，code-davinci-002似乎是具有所有强大能力的最强GPT-3.5模型。接下来通过有监督的instruction tuning和 RLHF通过牺牲模型能力换取与人类对齐，即对齐税。 RLHF 使模型能够生成更翔实和公正的答案，同时拒绝其知识范围之外的问题。</p>
<p>我们希望这篇文章能够帮助提供一个清晰的GPT评估图，并引发一些关于语言模型、instruction tuning和code tuning的讨论。最重要的是， <strong>我们希望这篇文章可以作为在开源社区内复现GPT-3.5的路线图。</strong></p>
<blockquote>
<p>“因为山就在那里。”——乔治·马洛里，珠穆朗玛峰探险先驱</p>
</blockquote>
<h4 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h4><p><a target="_blank" rel="noopener" href="https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756#cef4ffed7ee54302981ae7acb0fbc9f3">拆解追溯 GPT-3.5 各项能力的起源</a></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/GPT/">GPT</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/GPT/">GPT</a>
                    
                      <a class="hover-with-bg" href="/tags/AI/">AI</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/03/05/%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0--%EF%BC%88%E6%80%9D%E6%83%B3%EF%BC%89/">
                        <span class="hidden-mobile">框架+设计思想学习笔记</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.0/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      $('#local-search-input').on('click', function() {
        searchFunc(path, 'local-search-input', 'local-search-result');
      });
      $('#modalSearch').on('shown.bs.modal', function() {
        $('#local-search-input').focus();
      });
    })()
  </script>












  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
